import librosa
import numpy as np
import pyaudio
import wave
import os
import tensorflow as tf
from keras import layers, models
import soundfile as sf
import pickle
import noisereduce as nr

# WAV íŒŒì¼ì—ì„œ MFCC íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
def extract_mfcc_features(audio_file):
    y, sr = sf.read(audio_file)
    y, _ = librosa.effects.trim(y)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    mfcc_mean = np.mean(mfcc.T, axis=0)
    return mfcc_mean

# RNN ëª¨ë¸ ì •ì˜
def create_rnn_model(input_shape):
    model = models.Sequential()
    model.add(layers.Input(shape=input_shape))
    model.add(layers.SimpleRNN(64, activation='relu', return_sequences=False))
    model.add(layers.Dense(32, activation='relu'))
    model.add(layers.Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# ìŒì„± ë…¹ìŒ í•¨ìˆ˜ (WAV ì €ì¥ + ë…¸ì´ì¦ˆ ì œê±°)
def record_audio(filename, duration=5):
    os.makedirs(os.path.dirname(filename), exist_ok=True)

    p = pyaudio.PyAudio()
    format = pyaudio.paInt16
    channels = 1
    rate = 16000
    frames_per_buffer = 1024

    stream = p.open(format=format, channels=channels, rate=rate, input=True, frames_per_buffer=frames_per_buffer)
    print("Recording...")
    frames = [stream.read(frames_per_buffer) for _ in range(0, int(rate / frames_per_buffer * duration))]
    print("Recording finished.")

    stream.stop_stream()
    stream.close()
    p.terminate()

    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(channels)
        wf.setsampwidth(p.get_sample_size(format))
        wf.setframerate(rate)
        wf.writeframes(b''.join(frames))

    reduce_noise_from_audio(filename)

def reduce_noise_from_audio(filename):
    y, sr = librosa.load(filename, sr=16000)
    reduced_noise = nr.reduce_noise(y=y, sr=sr)
    sf.write(filename, reduced_noise, sr)
    print(f"Noise reduction applied to {filename}.")

# ì‚¬ìš©ì ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
def save_user_model(username, audio_file):
    features = extract_mfcc_features(audio_file)
    user_model = {'username': username, 'features': features}
    model_folder = f"C:\\AI\\models\\{username}"
    os.makedirs(model_folder, exist_ok=True)
    model_path = os.path.join(model_folder, f"{username}_model.pkl")

    with open(model_path, 'wb') as f:
        pickle.dump(user_model, f)
    print(f"{username}'s model has been saved at {model_path}.")

# ë¡œê·¸ì¸ ì¸ì¦ í•¨ìˆ˜ (RNN ëª¨ë¸ ì‚¬ìš©)
def authenticate_for_login_with_rnn():
    count_file = f"C:\\AI\\login\\login_count.txt"
    login_count = 0
    if os.path.exists(count_file):
        with open(count_file, 'r') as f:
            login_count = int(f.read().strip())
    login_count += 1
    audio_file = f"C:\\AI\\login\\login{login_count}.wav"

    print(f"{login_count}ë²ˆì§¸ ë¡œê·¸ì¸ ì‹œë„ ì¤‘ì…ë‹ˆë‹¤. ë§ì”€í•˜ì„¸ìš”.")
    record_audio(audio_file, duration=5)

    with open(count_file, 'w') as f:
        f.write(str(login_count))

    username = authenticate_user_with_rnn(audio_file)
    if username:
        print(f"{username}ë‹˜ì˜ ë¡œê·¸ì¸ ì„±ê³µ!")
    else:
        print("ë¡œê·¸ì¸ ì‹¤íŒ¨")

# ì‚¬ìš©ì ì¸ì¦ í•¨ìˆ˜
def authenticate_user_with_rnn(audio_file):
    input_features = extract_mfcc_features(audio_file)
    if input_features is None or np.all(input_features == 0):
        print("ìœ íš¨í•œ ìŒì„± ì…ë ¥ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    input_features = input_features.reshape((1, input_features.shape[0], 1))
    model_folder = "C:\\AI\\models"
    for user_folder in os.listdir(model_folder):
        model_path = os.path.join(model_folder, user_folder, 'voice_authentication_model.h5')
        if os.path.exists(model_path):
            model = tf.keras.models.load_model(model_path)
            prediction = model.predict(input_features)
            print(f"{user_folder}ì˜ ì˜ˆì¸¡ ê²°ê³¼: {prediction}")
            if prediction >= 0.92:
                return user_folder
    return None

# ì‚¬ìš©ì ë“±ë¡ í•¨ìˆ˜
def register_user(username):
    folder = f"C:\\AI\\audio\\{username}"
    os.makedirs(folder, exist_ok=True)

    files = [os.path.join(folder, f"{username}_register_{i + 1}.flac") for i in range(3)]
    print(f"{username}ë‹˜ì˜ ìŒì„±ì„ 3ë²ˆ ë…¹ìŒí•©ë‹ˆë‹¤.")

    features_list = []
    for i, path in enumerate(files):
        print(f"{i + 1}ë²ˆì§¸ ë…¹ìŒ ì‹œì‘")
        record_audio(path, duration=5)  # .flac íŒŒì¼ë¡œ ë…¹ìŒ
        mfcc = extract_mfcc_features(path)  # ìˆ˜ì •ëœ í•¨ìˆ˜ í˜¸ì¶œ
        features_list.append(mfcc)

    # ğŸ”½ ë¶€ì •(negative) ìŒì„± ì¶”ê°€
    negative_files = ["C:\\AI\\negative\\noise.wav", "C:\\AI\\negative\\silence.wav", "C:\\AI\\negative\\other.wav"]
    negative_features = [extract_mfcc_features(f) for f in negative_files]  # ìˆ˜ì •ëœ í•¨ìˆ˜ í˜¸ì¶œ

    # ì „ì²´ ë°ì´í„° ì¤€ë¹„
    X = np.array(features_list + negative_features)
    X = X.reshape((X.shape[0], X.shape[1], 1))
    y = np.array([1] * len(features_list) + [0] * len(negative_features))  # 1: ì‚¬ìš©ì, 0: ì•„ë‹Œ ìŒì„±

    model = create_rnn_model(input_shape=(X.shape[1], 1))
    model.fit(X, y, epochs=15)

    model_path = f"C:\\AI\\models\\{username}\\voice_authentication_model.h5"
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    model.save(model_path)
    print(f"{username}ë‹˜ì˜ ìŒì„± ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    while True:
        print("\në©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ë¡œê·¸ì¸")
        print("2. íšŒì›ê°€ì…")
        print("0. ì¢…ë£Œ")
        choice = input("ì„ íƒ (1/2/0): ")

        if choice == '1':
            authenticate_for_login_with_rnn()
        elif choice == '2':
            username = input("íšŒì›ê°€ì…í•  ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: ")
            register_user(username)
        elif choice == '0':
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
